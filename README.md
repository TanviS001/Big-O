# Learning Big-O Notation
Learn and practice Big O.

## What is Big O Notation?

Big O notation is a mathematical representation used to describe the performance or complexity of an algorithm. It specifically focuses on the worst-case scenario, providing an upper limit on the time or space complexity of an algorithm as the input size grows.

## Why is Big O Important?

- It helps evaluate the efficiency of algorithms.
- It allows for comparison between different algorithms.
- It provides insights into how an algorithm scales with input size.

## Common Big O Notations

- **O(1)**: Constant time - The algorithm's running time does not change with the size of the input.
- **O(log n)**: Logarithmic time - The running time grows logarithmically as the input size increases.
- **O(n)**: Linear time - The running time grows linearly with the input size.
- **O(n log n)**: Linearithmic time - Common in algorithms like mergesort.
- **O(nÂ²)**: Quadratic time - The running time grows quadratically with the input size, often seen in algorithms with nested loops.
- **O(2^n)**: Exponential time - The running time doubles with each additional input.
- **O(n!)**: Factorial time - Extremely inefficient, common in algorithms that generate all permutations.

## Resources

- [Big O Cheat Sheet](https://www.bigocheatsheet.com/)
